{"cells": [{"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}, {"cell_type": "markdown", "metadata": {}, "source": ["\\begin{center}\n", "\\begin{huge}\n", "MCIS6273 Data Mining (Prof. Maull) / Fall 2022 / HW2\n", "\\end{huge}\n", "\\end{center}\n", "\n", "| Points <br/>Possible | Due Date | Time Commitment <br/>(estimated) |\n", "|:---------------:|:--------:|:---------------:|\n", "| 20 | Monday, Oct 24 @ Midnight | _up to_ 24 hours |\n", "\n", "\n", "* **GRADING:** Grading will be aligned with the completeness of the objectives.\n", "\n", "* **INDEPENDENT WORK:** Copying, cheating, plagiarism  and academic dishonesty _are not tolerated_ by University or course policy.  Please see the syllabus for the full departmental and University statement on the academic code of honor.\n", "\n", "## OBJECTIVES\n", "* Learn more about the analysis of the FARS database.\n", "\n", "* Recreate data analysis in a published paper.\n", "\n", "* Perform cluster analysis on NHTSA FARS data.\n", "\n", "* Resubmit your PCA analysis from HW1.\n", "\n", "## WHAT TO TURN IN\n", "You are being encouraged to turn the assignment in using the provided\n", "Jupyter Notebook.  To do so, make a directory in your Lab environment called\n", "`homework/hw2`.   Put all of your files in that directory.  Then zip that directory,\n", "rename it with your name as the first part of the filename (e.g. `maull_hw2_files.zip`), then\n", "download it to your local machine, then upload the `.zip` to Blackboard.\n", "\n", "If you do not know how to do this, please ask, or visit one of the many tutorials out there\n", "on the basics of using zip in Linux.\n", "\n", "If you choose not to use the provided notebook, you will still need to turn in a\n", "`.ipynb` Jupyter Notebook and corresponding files according to the instructions in\n", "this homework.\n", "\n", "\n", "## ASSIGNMENT TASKS\n", "### (30%) Learn more about the analysis of the FARS database. \n", "\n", "In the last homework we learned about the FARS database, \n", "and actually USED it!\n", "\n", "While it might seem like a nice dataset to have (and it is),\n", "researchers have been using it for years to study\n", "transportation issues in this country, with the hopes of \n", "using the outcomes of these analyses for safety policy \n", "decisions.\n", "\n", "You will get a little more cozy with such research by \n", "reading the paper:\n", "\n", "> U. Roy, \u201cComparative Analysis of Fatal Pedestrian Crashes between Kansas and USA,\u201d JTTs, vol. 09, no. 03, pp. 381\u2013396, 2019, doi: [10.4236/jtts.2019.93024](https://doi.org/10.4236/jtts.2019.93024).\n", "\n", "\n", "As you will read, the phenomenon of pedestrian fatalities (involving automobiles) \n", "have been studied  in recent years -- and while relatively low, are not non-existent.  These\n", "fatalities have been on the rise, with no single reason for the change.\n", "\n", "It is important as a data scientist, that you be able to reference literature \n", "and assess its relevance to analysese you may be doing as a professional,\n", "and with datasets such as those in FARS, there are plenty of researchers\n", "trying to understand correlation and causes between\n", "the multitude of changes in the data.  \n", "\n", "In this paper (Roy, 2019), you see some familiar concepts and some unfamiliar, but\n", "you may come to understand a component of the data that we did not explore in\n", "the prior homework.\n", "\n", "You can download the paper free from one of the following sources:\n", "\n", "* [SemanticScholar link](https://pdfs.semanticscholar.org/e24d/8bd444783e8ea9fbd58e10cdf1232ae33081.pdf)\n", "\n", "Read the paper (it will take about an hour) and answer the questions below.\n", "\n", "**&#167; Task:**  Read the paper and write a 4-7 sentence (about a paragraph) \n", "_summary_.  State in your own words what you learned,\n", "what expanding your knowledge of the topic and what you found _interesting_\n", "about the information you received.  Please include the major points of the paper, \n", "and any weaknesses the authors point out with their research.\n", "\n", "\n", "**&#167; Task:**  Answer the following questions:\n", "\n", "(a) What time of day is most common for pedestrian fatalities in Kansas (over all years)?\n", "(b) How does this compare with the most common time of day for the US overall?\n", "(c) Looking at figure 11, would you say poor atmospheric conditions have a significant impact on pedestrial fatalities?\n", "(d) On page 392, the author states _\"For Kansas, speed limits between 30 mph and 40 mph \n", "    account for 52% of total crashes (26% crashes for 30 mph and 26% for 35 mph or 40mph), ...\"_.  Why is this\n", "    statement as written incorrect?\n", "(e) The authors go on to explain the abnormally high number of fatalities at higher speeds \n", "    with _\"... Kansas has lot of rural roads, where the speed limit is high and in \n", "    rural roads, laws are not strictly enforced, all of which might lead to a larger number\n", "    of fatal pedestrian crashes.\"_.  Which of the suggested countermeasures would you think \n", "    might successfully address this issue?  If you do not find anything sufficient, what\n", "    might you recommend instead?\n", "\n", "\n", "\n", "### (20%) Recreate data analysis in a published paper. \n", "\n", "As a data scientist, you must be prepared to defend the analyses and \n", "models that you create.  This is often done with workflow tools and\n", "processes which capture the full range of activities performed during\n", "an analysis.  Commercial tools are very good at this, but often\n", "simply organizing your notebooks will go a long way to \n", "keeping track of your analyses.\n", "\n", "In academic publishing, it is becoming more common for authors\n", "to submit data used in their papers. If the data was\n", "not already public, is it customary to ensure the released publication data does not\n", "violate the privacy or personally identifying information\n", "of others. It is also customary to make certain data was obtained \n", "in a way that the participants were\n", "aware that the data was going to be shared or otherwise given an option to decline \n", "to have such data publicly released.\n", "\n", "In the case of this paper, both datasets (the KARS and FARS) are  public.\n", "\n", "For this part of the assignment you will recreate some of the \n", "graphs in tha paper from part 1 above.  For all graph outputs, **you do \n", "  not need to recreate colors -- you can use the standard colors in Pandas and matplotlib.**\n", "\n", "**NOTE #1:** You will need to refer back to, and otherwise reuse, your work from\n", "your first homework to complete this part.\n", "\n", "**NOTE #2:** You will also find the `PERSONS.csv` file necessary to obtain ages.  This was NOT part\n", "of your original code, but extracting the required information will be very similar. Study \n", "it carefully to understand what you need to get from it.\n", "\n", "**&#167; Task:**  Recreate the graph (with actual FARS data) in Figure 15.  You do not need to show the \n", "Kansas data. **BONUS (up to to 3 points extra):** You will earn up to 3 bonus points added\n", "to this assignment if you \n", "access the KARS data set and perform the same analysis (in other words, \n", "you cannot just put the numbers in figure 15 in the graph and earn the bonus). \n", "\n", "\n", "**&#167; Task:**  Recreate Figure 4 and Figure 9. \n", "\n", "\n", "**&#167; Task:**  Take the data from Figure 4 and Figure 9 and combine them.  What you will end up with \n", "is a grouping by age band, then by time of day.  Your final graph will be able to answer\n", "questions about which age group is more or less likely to experience a pedestrian\n", "fatality during which time of day.\n", "\n", "\n", "\n", "### (50%) Perform cluster analysis on NHTSA FARS data. \n", "\n", "Now that we have data, let's analyze it.\n", "\n", "You will, by now, have watched the lectures on clustering and unsupervised learning \n", "algorithms.  You will know that clustering provides a significant tool for understanding\n", "underlying patterns in data and can be powerful in explaining the various aspects of \n", "your data.\n", "\n", "In this part, we will go one step further and begin to explore the patterns in the FARS \n", "dataset.\n", "\n", "**&#167; Task:**  _(Reshape the US dataset from HW1)_\n", "\n", "You will go back to the dataset in HW1 and begin the process of \n", "reshaping the data so that you will only include pedestrian fatalities,\n", "that is to say, you will only include fatalites with pedestrians.\n", "\n", "You will also need to make sure of the following:\n", "\n", "* you are using data from the 1975-2020 that you found in HW1 \n", "* you are including all states data **except Kansas**\n", "* restrict to _numeric features_, eliminate year as a feature\n", "* scale the data using [scikit-learn Standard Scaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html#sklearn.preprocessing.StandardScaler)\n", "\n", "You will end up with a new dataset which will only have pedestrian fatalities, \n", "numeric features and data scaled for 1975-2020.\n", "\n", "\n", "**&#167; Task:**  _(Perform ad hoc K-Means clustering)_\n", "\n", "You will now take the dataset from the first part and begin the process of \n", "clustering.\n", "\n", "To be successful, please study the following:\n", "\n", "* [K-Means in scikit-learn](https://scikit-learn.org/stable/modules/clustering.html#k-means)\n", "* [K-Means example notebook](https://nbviewer.jupyter.org/github/tmbdev/teaching-mmir/blob/master/30-kmeans.ipynb)\n", "\n", "You will set three $K$ to 5, 10 and 12.  You will need to report the centroids\n", "for each cluster and in words how you would describe that cluster.  I will give more guidance \n", "on this in a mini-session.\n", "\n", "\n", "**&#167; Task:**  _(Perform elbow analysis to find optimal cluster size)_\n", "\n", "In the first part, we chose the cluster size $K$.  Another way to do this \n", "is to analyze the change in within cluster sum of squares and \n", "determine when such value fails to change significantly.  In other words,\n", "when the addition of another cluster fails to significantly change\n", "the within cluster sum of squares, then you can be confident \n", "more clusters won't make a difference (increasing $K$ will no longer be \n", "relevant).\n", "\n", "This is often referred to as \"Elbow Analysis\" or the \"Elbow Method\" because \n", "you will visually find the elbow in a plot of the sum of squares \n", "and choose $K$ based on that. \n", "\n", "Study the following code, implement it, and find the optimal $K$ based on it.\n", "\n", "Your answer must include:\n", "\n", "* the elbow graph\n", "* the optimal $K$\n", "* the reanalysis of the previous answer based on the optimal $K$ (re-run your clusters and report their centroid characteristics)\n", "\n", "Here is the code to help you:\n", "\n", "```python\n", "max_clusters = 15\n", "css = [] # within cluster sum of squares\n", "\n", "for k in range(1,max_clusters):\n", "  kmeans = KMeans(n_clusters=k, 'k-means++', max_iter=200, n_init=10, random_state=0)\n", "  kmeans.fit(d) # where d is the dataset you have standardized in the first part of this\n", "  css.append(kmeans.inertia_)\n", "\n", "# now make a line plot of all the values in css     \n", "...\n", "```\n", "\n", "\n", "**&#167; Task:**  _(Find out where Kansas fits in)_\n", "\n", "Using the optimal $K$ found in your elbow analysis and understanding the \n", "characteristics of each representative in each cluster, which cluster \n", "would Kansas likely belong to?\n", "\n", "By extension, which states are most like Kansas (belong to the same cluster)\n", "regarding pedestrian fatalities?\n", "\n", "\n", "**&#167; Task:**  _(Perform Agglomorative Clustering)_\n", "\n", "One method also worth implementing is the hierarchical technique agglomorative clustering.  This clustering method\n", "has the benefit of interpretability and as mentioned in the lectures, can be a \n", "powerful technique to show how a cluster is partitioned and can give specific insights \n", "to the features of clusters themselves. Most often the output of the cluster is in the form \n", "of a dendrogram, but often these can be complex to show on a single screen or page \n", "without scrolling.\n", "\n", "To be successful you will need to study the following:\n", "\n", "* [main sklearn api to AgglomerativeClustering](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.AgglomerativeClustering.html)\n", "* [plotting the dendrogram](https://scikit-learn.org/stable/auto_examples/cluster/plot_agglomerative_dendrogram.html#sphx-glr-auto-examples-cluster-plot-agglomerative-dendrogram-py)\n", "\n", "Set the parameter `n_clusters` to the same value found in your work above.\n", "\n", "\n", "\n"]}], "metadata": {"anaconda-cloud": {}, "kernelspec": {"display_name": "Python [default]", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.1"}, "toc": {"colors": {"hover_highlight": "#DAA520", "navigate_num": "#000000", "navigate_text": "#333333", "running_highlight": "#FF0000", "selected_highlight": "#FFD700", "sidebar_border": "#EEEEEE", "wrapper_background": "#FFFFFF"}, "moveMenuLeft": true, "nav_menu": {"height": "12px", "width": "252px"}, "navigate_menu": true, "number_sections": false, "sideBar": true, "threshold": "1", "toc_cell": false, "toc_section_display": "block", "toc_window_display": true, "widenNotebook": false}}, "nbformat": 4, "nbformat_minor": 0}